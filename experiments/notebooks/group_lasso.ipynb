{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Group Lasso Notebook\n",
        "\n",
        "To use this notebook, put the appropriate Chemistry Data in a folder in Google Drive, after mounting the drive it is crucial to select the correct folder, which is the first line of this notebook:\n",
        "\n",
        "foldername = 'gdrive/MyDrive/'\n",
        "\n",
        "Edit this to have the correct foldername.\n",
        "\n",
        "Also install group-lasso with the second line of this notebook.\n",
        "\n",
        "After that it is fairly easy to run. Hyperparameters can be changed, and in the Run Experiment part of the notebook one can run a synthetic or chemistry experiment easily with:\n",
        "\n",
        "run_syn(rule=4, experiment_no=1)\n",
        "\n",
        "or\n",
        "\n",
        "run_chem(rule=2, experiment_no=1)"
      ],
      "metadata": {
        "id": "gOsIqAq42qWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foldername = 'gdrive/MyDrive/'"
      ],
      "metadata": {
        "id": "zIRpITpX2_zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kJCu06RTRWA",
        "outputId": "34a50610-8138-49f9-872d-96f547b2add7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: group-lasso in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from group-lasso) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from group-lasso) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->group-lasso) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install group-lasso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import comb\n",
        "import numpy as np\n",
        "import itertools\n",
        "from functools import reduce\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "from group_lasso import LogisticGroupLasso\n",
        "LogisticGroupLasso.LOG_LOSSES = True"
      ],
      "metadata": {
        "id": "OKGMXBwtQNjA"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgSKt_n2mOXe",
        "outputId": "e0a693f7-5b0a-4e2c-8360-61d2e8b117cc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change the hyperparameters here:"
      ],
      "metadata": {
        "id": "0ZhWCO5CZ8Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_group_size = 2        # Max group size, to prevent the problem getting exponenetially large.\n",
        "n_iterations_syn = 1000   # Max number of iterations on syn before Group Lasso Stops.\n",
        "n_iterations_chem = 100   # Max number of iterations on chem before Group Lasso Stops.\n",
        "eps = 0.005               # If a group has weight ||w||_2 > eps it is selected."
      ],
      "metadata": {
        "id": "EVsrIf_nMKN5"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for Running"
      ],
      "metadata": {
        "id": "I0yYGkXKbk4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gsim(true_groups, predicted_groups):\n",
        "    # Returns gsim, number of true groups, and number of discovered groups, given\n",
        "    # true groups and predicted groups as input.\n",
        "    gsim = 0\n",
        "    if len(true_groups) == 0: # i.e. we don't know the ground truth.\n",
        "       return -1, len(true_groups), len(predicted_groups)\n",
        "    if len(predicted_groups)>0:\n",
        "      for g in true_groups:\n",
        "         current_max = 0\n",
        "         for g_hat in predicted_groups:\n",
        "            jac = np.intersect1d(g, g_hat).size / np.union1d(g, g_hat).size\n",
        "            if jac == 1:\n",
        "               current_max = 1\n",
        "               break\n",
        "            if jac > current_max:\n",
        "               current_max = jac\n",
        "         gsim += current_max\n",
        "      gsim /= max(len(true_groups), len(predicted_groups))\n",
        "      return gsim, len(true_groups), len(predicted_groups)\n",
        "    else:   # We didn't find anything.\n",
        "      return 0, len(true_groups), len(predicted_groups)\n",
        "\n",
        "\n",
        "def tpr_fdr(true_groups, predicted_groups):\n",
        "   # True positive rate and false discovery rate.\n",
        "   \n",
        "   if len(true_groups) == 0:  # Ground truth not known.\n",
        "      return -1, -1\n",
        "\n",
        "   if len(predicted_groups) == 0:\n",
        "      return 0.0, 0.0\n",
        "\n",
        "   predicted_features = np.unique(reduce(np.union1d, predicted_groups))\n",
        "   true_features = np.unique(reduce(np.union1d, true_groups))\n",
        "\n",
        "   overlap = np.intersect1d(predicted_features, true_features).size\n",
        "   tpr = 100*overlap/len(true_features)\n",
        "   fdr = 100*(len(predicted_features)-overlap)/len(predicted_features) # If len(predicted_features) != 0 else 0.0.\n",
        "   return tpr, fdr"
      ],
      "metadata": {
        "id": "L8z2RuB6eusS"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logic Rules\n",
        "\n",
        "def rule1(x_sample):\n",
        "    return (x_sample[0] > 0.55) or (x_sample[1] > 0.55)\n",
        "\n",
        "def rule2(x_sample):\n",
        "    return (x_sample[0]*x_sample[1] > 0.30) or (x_sample[2]*x_sample[3] > 0.30)\n",
        "\n",
        "def rule3(x_sample):\n",
        "    return (x_sample[0]*x_sample[1] > 0.30) or (x_sample[0]*x_sample[2] > 0.30)\n",
        "\n",
        "def rule4(x_sample):\n",
        "    return (x_sample[0]*x_sample[3] > 0.30) or (x_sample[6]*x_sample[9] > 0.30)"
      ],
      "metadata": {
        "id": "WrEE65WXYjhv"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling rules\n",
        "\n",
        "def normal_sample(nsamples, nfeatures):\n",
        "    return np.random.normal(size=(nsamples, nfeatures))\n",
        "\n",
        "def correlated_sample(nsamples, nfeatures):\n",
        "    mean = np.array([0.0, 0.0, 0.0])\n",
        "    cov = np.array([[1, 0.99, 0.99],\n",
        "                    [0.99, 1, 0.99],\n",
        "                    [0.99, 0.99, 1]])\n",
        "\n",
        "    x123 = np.random.multivariate_normal(mean, cov, size=nsamples)\n",
        "    x456 = np.random.multivariate_normal(mean, cov, size=nsamples)\n",
        "    x789 = np.random.multivariate_normal(mean, cov, size=nsamples)\n",
        "    x101112 = np.random.multivariate_normal(mean, cov, size=nsamples)\n",
        "    xrest = np.random.normal(size=(nsamples, nfeatures-4*3))\n",
        "    return np.concatenate([x123, x456, x789, x101112, xrest], axis=1)"
      ],
      "metadata": {
        "id": "QURYB6WQZNiU"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_base_experiment(X_train, y_train, X_test, y_test, true_groups, reg_param, n_iterations):\n",
        "\n",
        "    # Construct groups - duplicate features.\n",
        "    X_group_lasso_train = np.array([])\n",
        "    X_group_lasso_test = np.array([])\n",
        "    groups = []\n",
        "    groups_tuple = []\n",
        "    g_num = 0\n",
        "\n",
        "    print('Constructing Groups')\n",
        "    for n in range(1, max_group_size+1):\n",
        "        for comb in itertools.combinations(list(range(X_train.shape[1])), n):\n",
        "            X_group_lasso_train = np.concatenate([X_group_lasso_train, X_train[:,comb]], axis=1) if X_group_lasso_train.size else np.array(X_train[:,comb])\n",
        "            X_group_lasso_test = np.concatenate([X_group_lasso_test, X_test[:,comb]], axis=1) if X_group_lasso_test.size else np.array(X_test[:,comb])\n",
        "            groups.extend([g_num]*len(comb))\n",
        "            g_num+=1\n",
        "            groups_tuple += [comb]\n",
        "    print('Constructing Groups complete')\n",
        "\n",
        "    print('X_Group_Train shape: {}'.format(X_group_lasso_train.shape))\n",
        "    print('y_Train shape: {}'.format(y_train.shape))\n",
        "    print('X_Group_Test shape: {}'.format(X_group_lasso_test.shape))\n",
        "    print('y_Test shape: {}'.format(y_test.shape))\n",
        "    print('Number of possible groups: {}\\n'.format(len(groups_tuple)))\n",
        "\n",
        "    gl = LogisticGroupLasso(\n",
        "        groups=groups,\n",
        "        n_iter=n_iterations,\n",
        "        group_reg=reg_param,\n",
        "        l1_reg=0.0,\n",
        "        scale_reg='group_size',\n",
        "        supress_warning=True,\n",
        "    )\n",
        "\n",
        "    print('Training started')\n",
        "    gl.fit(X_group_lasso_train, y_train)\n",
        "    print('Training complete\\n')\n",
        "\n",
        "\n",
        "    # Extract info from estimator\n",
        "    pred = gl.predict(X_group_lasso_test)\n",
        "\n",
        "    # Compute performance metrics\n",
        "    accuracy = (pred == y_test).mean()\n",
        "\n",
        "    # get groups\n",
        "    w_hat = gl.coef_\n",
        "    w_hat = w_hat[:, 1] - w_hat[:, 0]\n",
        "    group_sizes = np.zeros(groups[-1]+1)\n",
        "\n",
        "    for f, w in zip(groups, w_hat):\n",
        "        group_sizes[f] += w**2\n",
        "    group_sizes = group_sizes**0.5\n",
        "\n",
        "    chosen_groups = np.where(group_sizes>eps)[0]\n",
        "    check_acc = 100*(((X_group_lasso_train @ w_hat)>0)==y_train).mean()\n",
        "\n",
        "    # Print results.\n",
        "    print('Results:\\n')\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "    print(f\"Check Test Accuracy is Close to Train Accuracy: {check_acc}\")\n",
        "    print('Chosen Groups:')\n",
        "    for g in chosen_groups:\n",
        "        print('     Group: {}, {}'.format(g, groups_tuple[g]))\n",
        "\n",
        "    discovered_groups = [np.array(list(groups_tuple[g])) for g in chosen_groups]\n",
        "\n",
        "    tpr, fdr = tpr_fdr(true_groups, discovered_groups)\n",
        "    group_sim, ntrue, npredicted = gsim(true_groups, discovered_groups)\n",
        "\n",
        "    print('\\nGroup Similarity: {:.3f}\\nTrue Positive Rate: {:.3f}%\\nFalse Discovery Rate: {:.3f}%'.format(group_sim, tpr, fdr))\n",
        "    print('Number of True Groups: {}\\nNumber of Predicted Groups: {}'.format(ntrue, npredicted))"
      ],
      "metadata": {
        "id": "kGMLiJ_ppPV_"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_syn(rule, experiment_no):\n",
        "\n",
        "    print('Running Syn{}'.format(rule))\n",
        "    n_iterations = n_iterations_syn\n",
        "    gauss_gt_groups = {\n",
        "        1: [np.array([0]), np.array([1])], \n",
        "        2: [np.array([0, 1]), np.array([2, 3])],\n",
        "        3: [np.array([0, 1]), np.array([0, 2])],\n",
        "        4: [np.array([0, 3]), np.array([6, 9])]\n",
        "    }\n",
        "\n",
        "    group_regs = {\n",
        "        1: 0.1,\n",
        "        2: 0.04,\n",
        "        3: 0.04,\n",
        "        4: 0.04\n",
        "    }\n",
        "\n",
        "    sampling_rules = {\n",
        "        1: normal_sample,\n",
        "        2: normal_sample,\n",
        "        3: normal_sample,\n",
        "        4: correlated_sample\n",
        "    }\n",
        "\n",
        "    logic_rules = {\n",
        "        1: rule1,\n",
        "        2: rule2,\n",
        "        3: rule3,\n",
        "        4: rule4\n",
        "    }\n",
        "\n",
        "    np.random.seed(experiment_no)\n",
        "    X_train = sampling_rules[rule](nsamples=1000, nfeatures=60)\n",
        "    y_train = np.array([logic_rules[rule](x) for x in X_train])\n",
        "    X_test = sampling_rules[rule](nsamples=100, nfeatures=60)\n",
        "    y_test = np.array([logic_rules[rule](x) for x in X_test])\n",
        "\n",
        "    true_groups = gauss_gt_groups[rule]\n",
        "    reg_param = group_regs[rule]\n",
        "    run_base_experiment(X_train, y_train, X_test, y_test, true_groups, reg_param)"
      ],
      "metadata": {
        "id": "pfAXCtB1sIFZ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chem(rule, experiment_no):\n",
        "\n",
        "    print('Running Chem{}'.format(rule))\n",
        "    n_iterations = n_iterations_chem\n",
        "    np.random.seed(experiment_no)\n",
        "\n",
        "    rules = {\n",
        "        1: 4,\n",
        "        2: 10,\n",
        "        3: 13\n",
        "    }\n",
        "    rule = rules[rule]\n",
        "\n",
        "    chem_data_groups = {4: [np.array([40]), np.array([1])], # logic_4 = ether OR NOT alkyne\n",
        "\t\t            10: [np.array([56, 18]), np.array([40])], # logic_10 = (primary amine AND NOT ether) OR (NOT benzene AND NOT ether)\n",
        "\t\t            13: [np.array([18, 29]), np.array([1, 40])]} # logic_13 = (benzene AND NOT carbonyl) OR (alkyne AND NOT ether)\n",
        "\n",
        "    group_regs = {\n",
        "        4: 0.04,\n",
        "        10: 0.04,\n",
        "        13: 0.04\n",
        "    }\n",
        "\n",
        "    \n",
        "    X_train = np.load(osp.join(foldername, 'logic_'+str(rule)+'_X_train.npy'))\n",
        "    y_train = np.load(osp.join(foldername, 'logic_'+str(rule)+'_Y_train.npy'))\n",
        "\n",
        "    X_test = np.load(osp.join(foldername, 'logic_'+str(rule)+'_X_test.npy'))\n",
        "    y_test = np.load(osp.join(foldername, 'logic_'+str(rule)+'_Y_test.npy'))\n",
        "\n",
        "    true_groups = chem_data_groups[rule]\n",
        "    reg_param = group_regs[rule]\n",
        "    run_base_experiment(X_train, y_train, X_test, y_test, true_groups, reg_param, n_iterations)\n"
      ],
      "metadata": {
        "id": "Hr5nvo5ynrSP"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Experiment"
      ],
      "metadata": {
        "id": "iV51TCWRbqG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_syn(rule=1, experiment_no=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGSXA4AeubFY",
        "outputId": "49c439eb-0a27-4773-e5d2-460615f6e6d1"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Syn1\n",
            "Constructing Groups\n",
            "Constructing Groups complete\n",
            "X_Group_Train shape: (1000, 3600)\n",
            "y_Train shape: (1000,)\n",
            "X_Group_Test shape: (100, 3600)\n",
            "y_Test shape: (100,)\n",
            "Number of possible groups: 1830\n",
            "\n",
            "Training started\n",
            "Training complete\n",
            "\n",
            "Results:\n",
            "\n",
            "Test Accuracy: 0.79\n",
            "Check Test Accuracy is Close to Train Accuracy: 80.9\n",
            "Chosen Groups:\n",
            "     Group: 0, (0,)\n",
            "     Group: 1, (1,)\n",
            "     Group: 60, (0, 1)\n",
            "\n",
            "Group Similarity: 0.667\n",
            "True Positive Rate: 100.000%\n",
            "False Discovery Rate: 0.000%\n",
            "Number of True Groups: 2\n",
            "Number of Predicted Groups: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
            "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_chem(rule=1, experiment_no=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G3rrOc5uVPX",
        "outputId": "d35a2aa1-2288-4500-a346-01cc2e8466a1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Chem1\n",
            "Constructing Groups\n",
            "Constructing Groups complete\n",
            "X_Group_Train shape: (3861, 7056)\n",
            "y_Train shape: (3861,)\n",
            "X_Group_Test shape: (466, 7056)\n",
            "y_Test shape: (466,)\n",
            "Number of possible groups: 3570\n",
            "\n",
            "Training started\n",
            "Training complete\n",
            "\n",
            "Results:\n",
            "\n",
            "Test Accuracy: 1.0\n",
            "Check Test Accuracy is Close to Train Accuracy: 75.26547526547527\n",
            "Chosen Groups:\n",
            "     Group: 1, (1,)\n",
            "     Group: 40, (40,)\n",
            "     Group: 205, (1, 40)\n",
            "\n",
            "Group Similarity: 0.667\n",
            "True Positive Rate: 100.000%\n",
            "False Discovery Rate: 0.000%\n",
            "Number of True Groups: 2\n",
            "Number of Predicted Groups: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/group_lasso/_fista.py:119: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
            "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    }
  ]
}